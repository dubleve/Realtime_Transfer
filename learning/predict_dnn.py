# -*- coding: utf-8 -*-
"""predict_dnn.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-o4LnI18cCsFGhjWevbKjIdVDTcL_lXA
"""


# Import
import tensorflow as tf
import pandas as pd
import json
import numpy as np
from firebase import firebase

class NumpyEncoder(json.JSONEncoder):
  def default(self, obj):
    if isinstance(obj, np.ndarray):
      return obj.tolist()
    return json.JSONEncoder.default(self, obj)


#Import datasets & set datasets
firebase = firebase.FirebaseApplication('https://pnu-dubleve.firebaseio.com/')


X_data = list()

def load(x):
  n_datasets = int(raw_input('Please type the number of datasets : '))
  filename = raw_input('Please type the name of files : ')
  path = './datasets/labeled_data'
  for i in range(2, n_datasets):
      file= pd.read_csv(path + filename + str(i) + '.csv')
      dataset = file.values.tolist()
      for row in dataset:
        rows =list()
        for column in row:
          rows.append(column.split())
        rowdata = [list(map(int,i)) for i in rows]
        x.append(rowdata[0])


load(X_data)

X = tf.placeholder(tf.float32)

W1 = tf.Variable(tf.random_uniform([100, 50], -1., 1.))
W2 = tf.Variable(tf.random_uniform([50, 2], -1., 1.))
b1 = tf.Variable(tf.zeros([50]))
b2 = tf.Variable(tf.zeros([2]))

L1 = tf.add(tf.matmul(X, W1), b1)
Y = tf.nn.softmax(tf.matmul(L1, W2) + b2)

saver = tf.train.Saver()
init_op = tf.global_variables_initializer()

with tf.Session() as sess:
  sess.run(init_op)
  save_path = './model/dnn.ckpt'
  saver.restore(sess, tf.train.latest_checkpoint('./model/'))
  predictions = sess.run(Y, feed_dict={X: X_data})

#  result1 = firebase.put('Results/Result_01', 'Status', '?')
#  result2 = firebase.put('Results/Result_01', 'Who', '?')
  firebase.put('Results/test', 'result', json.dumps(predictions, cls=NumpyEncoder))

  print("successful");


